1. without Deep Supervision
2. dice_coef_loss as training loss


def Unet_scheduler(epoch, lr):
    if epoch < 2:
        return lr
    elif epoch < 5:
        return 5e-4
    elif epoch < 10:
        return 2e-4
    else:
        return lr * tf.math.exp(-0.05)


    EPOCHES = 50
    LR = 8e-4
    STEPS = 300
    BATCH_SIZE = 1
    TARGET_SIZE = (256, 256)